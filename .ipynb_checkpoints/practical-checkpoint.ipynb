{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp38-cp38-macosx_10_9_x86_64.whl (24.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.0 MB 853 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /Users/kcollins/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/kcollins/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 1800, num test: 200\n",
      "tot num reviews: 2000\n",
      "--- classifying reviews using sentiment lexicon  ---\n",
      "token-only results: 0.68\n",
      "magnitude results: 0.69\n",
      "magnitude lexicon results are not significant with respect to token-only\n",
      "--- classifying reviews using SVM 10-fold cross-eval ---\n"
     ]
    }
   ],
   "source": [
    "from Corpora import MovieReviewCorpus\n",
    "from Lexicon import SentimentLexicon\n",
    "from Statistics import SignTest\n",
    "from Classifiers import NaiveBayesText, SVMText\n",
    "from Extensions import SVMDoc2Vec\n",
    "\n",
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "# use sign test for all significance testing\n",
    "signTest=SignTest()\n",
    "\n",
    "print(\"--- classifying reviews using sentiment lexicon  ---\")\n",
    "\n",
    "# read in lexicon\n",
    "lexicon=SentimentLexicon()\n",
    "\n",
    "# on average there are more positive than negative words per review (~7.13 more positive than negative per review)\n",
    "# to take this bias into account will use threshold (roughly the bias itself) to make it harder to classify as positive\n",
    "threshold=8\n",
    "\n",
    "# NOTE: from katie to self -- play w/ changing the threshold value! \n",
    "\n",
    "# question 0.1\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=False)\n",
    "token_preds=lexicon.predictions\n",
    "print(f\"token-only results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=True)\n",
    "magnitude_preds=lexicon.predictions\n",
    "print(f\"magnitude results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "# question 0.2\n",
    "p_value=signTest.getSignificance(token_preds,magnitude_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"magnitude lexicon results are {significance} with respect to token-only\")\n",
    "\n",
    "# TODO Q6 and 6.1\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 1800, num test: 200\n",
      "tot num reviews: 2000\n",
      "--- classifying reviews using sentiment lexicon  ---\n",
      "token-only results: 0.68\n",
      "magnitude results: 0.69\n",
      "magnitude lexicon results are not significant with respect to token-only\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "# use sign test for all significance testing\n",
    "signTest=SignTest()\n",
    "\n",
    "print(\"--- classifying reviews using sentiment lexicon  ---\")\n",
    "\n",
    "# read in lexicon\n",
    "lexicon=SentimentLexicon()\n",
    "\n",
    "# on average there are more positive than negative words per review (~7.13 more positive than negative per review)\n",
    "# to take this bias into account will use threshold (roughly the bias itself) to make it harder to classify as positive\n",
    "threshold=8\n",
    "\n",
    "# NOTE: from katie to self -- play w/ changing the threshold value! \n",
    "\n",
    "# question 0.1\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=False)\n",
    "token_preds=lexicon.predictions\n",
    "print(f\"token-only results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=True)\n",
    "magnitude_preds=lexicon.predictions\n",
    "print(f\"magnitude results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "# question 0.2\n",
    "p_value=signTest.getSignificance(token_preds,magnitude_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"magnitude lexicon results are {significance} with respect to token-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcollins/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2,), (700,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(corpus.reviews)\n",
    "np.shape(corpus.reviews[0]), np.shape(corpus.reviews[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SVM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3d8e6ccd3f22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractReviewTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'SVM' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "sparse.csr_matrix(SVM.extractReviewTokens(corpus.reviews[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-2ede93d05091>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = v.fit_transform(Counter(f) for f in np.array(review_tokens))\n"
     ]
    }
   ],
   "source": [
    "# help from: https://stackoverflow.com/questions/46965524/create-sparse-word-matrix-in-python-bag-of-words\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "review_tokens = [np.array(SVM.extractReviewTokens(review[1])) for review in corpus.reviews]\n",
    "v = DictVectorizer()\n",
    "# get vocab and get sparse vectors\n",
    "X = v.fit_transform(Counter(f) for f in np.array(review_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x55384 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 347 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcollins/MLMI13/Classifiers.py:274: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'disenchanted',\n",
       " 'paydollars',\n",
       " 'uh',\n",
       " 'swastika',\n",
       " 'suspend',\n",
       " 'Spats',\n",
       " 'emotion-You',\n",
       " 'andon',\n",
       " 'Neanderthal',\n",
       " 'presumption',\n",
       " 'FILMMAKERS',\n",
       " 'Scream',\n",
       " 'sub',\n",
       " 'hacker',\n",
       " 'whiney',\n",
       " 'smidgeon',\n",
       " 'bartenders',\n",
       " 'anti-establishment',\n",
       " 'diagnosed',\n",
       " 'secondhand',\n",
       " 'Masterminds',\n",
       " 'pierce',\n",
       " 'Blanchett',\n",
       " 'knucklehead',\n",
       " 'styles',\n",
       " 'much-prized',\n",
       " 'Iggy-esuqe',\n",
       " '11-story',\n",
       " 'Jocelyn',\n",
       " 'frightened',\n",
       " 'SCREAM-esque',\n",
       " 'unstructured',\n",
       " 'pitchfork',\n",
       " 'that',\n",
       " 'fastened',\n",
       " '3\\xa01/2',\n",
       " 'Brite',\n",
       " 'maxim',\n",
       " 'sunlit',\n",
       " 'literalized',\n",
       " 'butts',\n",
       " 'British',\n",
       " 'CHEAP',\n",
       " 'sword-fight',\n",
       " 'horizons',\n",
       " 'monstrous',\n",
       " 'sketches',\n",
       " 'eagles',\n",
       " 'understandable-genre',\n",
       " 'puff-piece',\n",
       " 'Sipes',\n",
       " 'dim-wittedness',\n",
       " 'hills',\n",
       " 'melt',\n",
       " 'PO',\n",
       " 'observational',\n",
       " 'Green',\n",
       " 'audience-unfriendly',\n",
       " 'Sinbad',\n",
       " 'alienating',\n",
       " 'mushroom-cloud',\n",
       " 'bumbling',\n",
       " 'analytic',\n",
       " 'intuitive',\n",
       " 'Patton',\n",
       " 'time-to-time',\n",
       " 'Before',\n",
       " 'Gracie',\n",
       " 'constrained',\n",
       " 'ofmovies',\n",
       " 'class-divided',\n",
       " 'jam',\n",
       " 'Thrilling',\n",
       " 'KGB',\n",
       " 'Renee',\n",
       " 'Linney',\n",
       " 'caves',\n",
       " 'kegger',\n",
       " 'outcome',\n",
       " 'bodies',\n",
       " 'virtual-reality',\n",
       " 'swords',\n",
       " 'TRAP-ish',\n",
       " 'voice-it',\n",
       " 'legend',\n",
       " 'big-league',\n",
       " 'terrify',\n",
       " 'loser',\n",
       " 'Hughley',\n",
       " 'Stinks',\n",
       " 'Cup',\n",
       " 'crisp',\n",
       " 'mutinies',\n",
       " 'sell-out',\n",
       " 'deprivation',\n",
       " 'intricately-woven',\n",
       " 'arisen',\n",
       " 'screening',\n",
       " 'Gene',\n",
       " 'slumming',\n",
       " 'beout',\n",
       " 'BRIDE',\n",
       " 'admiting',\n",
       " 'Irishman',\n",
       " 'Mullen',\n",
       " 'ensnare',\n",
       " 'MA',\n",
       " 'Sharif',\n",
       " 'tee-shirts',\n",
       " 'taels',\n",
       " 'self-healing',\n",
       " 'firepower',\n",
       " 'Scottish',\n",
       " 'stimulation',\n",
       " 'behaving',\n",
       " 'Nathan',\n",
       " 'misfortunes',\n",
       " 'Sharks',\n",
       " 'gloss',\n",
       " 'overblown',\n",
       " 'monger',\n",
       " 'curse',\n",
       " 'Savannah',\n",
       " 'pigeon',\n",
       " 'tinder',\n",
       " 'EDGE',\n",
       " 'ABOUT',\n",
       " 'cliquey',\n",
       " 'Dorado',\n",
       " 'entertainers',\n",
       " 'replenish',\n",
       " 'Fflewdurr',\n",
       " 'ignoramus',\n",
       " 'FIFTH',\n",
       " 'low-traffic',\n",
       " 'horror/comedies',\n",
       " 'Whitewater',\n",
       " 'characterizing',\n",
       " 'lopped',\n",
       " 'alien',\n",
       " 'lively',\n",
       " 'ways-I',\n",
       " 'snugly',\n",
       " 'unerotic',\n",
       " 'hypothetically',\n",
       " 'soon-to-become-beleaguered',\n",
       " 'salacious',\n",
       " 'counselor',\n",
       " 'sneak-outs',\n",
       " 'prejudge',\n",
       " 'overused',\n",
       " 'tautly',\n",
       " 'AC/DC',\n",
       " '20s',\n",
       " 'Gen-Xer',\n",
       " 'discount',\n",
       " 'taunts',\n",
       " 'Colin',\n",
       " 'dilemmas',\n",
       " 'snickers',\n",
       " 'NIGHTHAWKS',\n",
       " 'cross-cutting',\n",
       " 'Spoon',\n",
       " 'professionalism',\n",
       " 'PERMANENT',\n",
       " 'warbling',\n",
       " 'Stemple',\n",
       " 'assumption',\n",
       " 'hanky-panky',\n",
       " 'dextrous',\n",
       " 'initiates',\n",
       " 'bountiful',\n",
       " 'Tostitos',\n",
       " 'eyeballed',\n",
       " 'Mailer',\n",
       " 'GUEST',\n",
       " 'reworked',\n",
       " 'love-she',\n",
       " 'bubble',\n",
       " 'savaged',\n",
       " 'wellness',\n",
       " 'Viggo',\n",
       " 'non-thrilling',\n",
       " '78',\n",
       " 'Maka',\n",
       " 'Grodin',\n",
       " 'stocked',\n",
       " 'total',\n",
       " 'loverboy',\n",
       " 'battlefields',\n",
       " 'Blatty',\n",
       " 'economical',\n",
       " 'Repeated',\n",
       " 'lingered',\n",
       " 'repackaging',\n",
       " 'wrestling',\n",
       " 'ni-sen',\n",
       " '1940s-style',\n",
       " 'Sumptuous',\n",
       " 'HEAT',\n",
       " 'streetcorner',\n",
       " 'Excuse',\n",
       " 'walnuts',\n",
       " 'low-tech',\n",
       " 'Johnston',\n",
       " 'bedmates',\n",
       " 'any',\n",
       " 'thanks',\n",
       " 'quirk',\n",
       " 'Windsor',\n",
       " 'survive',\n",
       " 'Tailor',\n",
       " 'pox',\n",
       " 'Mazar',\n",
       " 'unheard',\n",
       " 'laser',\n",
       " 'slathers',\n",
       " 'airy',\n",
       " 'attachs',\n",
       " 'electronics',\n",
       " 'Tinseltown',\n",
       " 'Bobbitt',\n",
       " 'straight-arrow',\n",
       " 'barnyard',\n",
       " 'bile',\n",
       " 'SKIP',\n",
       " 'punish',\n",
       " 'refill',\n",
       " 'still-active',\n",
       " 'Screwed',\n",
       " 'emrboidered',\n",
       " 'Silvers',\n",
       " 'bang',\n",
       " 'redneck',\n",
       " 'MARS',\n",
       " 'advises',\n",
       " '1,000-foot',\n",
       " 'Finding',\n",
       " 'goes',\n",
       " 'Petra',\n",
       " 'responses',\n",
       " 'elaborately',\n",
       " 'not-so-innocent',\n",
       " 'Sabor',\n",
       " 'Springtime',\n",
       " 'ex-gangsta',\n",
       " 'anti-gun',\n",
       " 'hypnotized',\n",
       " 'Using',\n",
       " 'adroitly',\n",
       " 'slight',\n",
       " 'rediscovering',\n",
       " 'uninterested',\n",
       " 'tend',\n",
       " 'subjective',\n",
       " 'Ifans',\n",
       " 'symbolic',\n",
       " 'purpose',\n",
       " 'equipped',\n",
       " 'iron',\n",
       " 'inhibitions',\n",
       " 'remarrying',\n",
       " 'emotionally',\n",
       " 'sham',\n",
       " 'fruits',\n",
       " 'paradise/prison',\n",
       " 'Dust',\n",
       " 'akin',\n",
       " 'ride',\n",
       " 'MIGHTY',\n",
       " 'Ferdinand',\n",
       " 'collector',\n",
       " 'goregeous',\n",
       " 'biology',\n",
       " 'wan',\n",
       " 'arching',\n",
       " 'deserves',\n",
       " 'I-THE',\n",
       " 'bribed',\n",
       " 'daft',\n",
       " 'Flowers',\n",
       " 'detractions',\n",
       " 'attendent',\n",
       " 'infectious',\n",
       " 'incompetents',\n",
       " 'Jnr',\n",
       " 'Carey',\n",
       " 'window',\n",
       " 'dissertations',\n",
       " 'shortcoming',\n",
       " 'dinosaur-sized',\n",
       " 'Pacing',\n",
       " 'Portman',\n",
       " 'Crosby',\n",
       " 'Forward',\n",
       " 'generalize',\n",
       " 'blondie',\n",
       " 'SHOPGIRL',\n",
       " 'formed',\n",
       " 're-enactment',\n",
       " 'Towners',\n",
       " 'unconditionally',\n",
       " 'Harlan',\n",
       " 'Sethe',\n",
       " 'sidewinder',\n",
       " 'DeGeneres',\n",
       " 'devastated',\n",
       " 'scenic',\n",
       " 'indigenous',\n",
       " 'amidst',\n",
       " 'The',\n",
       " 'Gratuitous',\n",
       " 'wielded',\n",
       " 'reveal',\n",
       " 'distraction',\n",
       " 'Lau',\n",
       " 'lunkheads',\n",
       " 'Hype',\n",
       " 'elitists',\n",
       " 'excerpted',\n",
       " 'reevaluation',\n",
       " 'subscribe',\n",
       " 'manipulate',\n",
       " 'masturbator',\n",
       " 'CONDOR',\n",
       " 'kitchen',\n",
       " 'andstarsfor',\n",
       " 'Robbi',\n",
       " 'destitute',\n",
       " 'dizzying',\n",
       " 'senatorial',\n",
       " 'foremost',\n",
       " 'shut',\n",
       " 'caraciture',\n",
       " 'Striptease',\n",
       " 'honkey',\n",
       " 'ze',\n",
       " 'spanking',\n",
       " 'assailing',\n",
       " 'arsenic',\n",
       " 'mission',\n",
       " 'SYMBOL',\n",
       " 'entails',\n",
       " 'Hot',\n",
       " 'discerning',\n",
       " 'crowd-pleasing',\n",
       " 'Cannibalism',\n",
       " 'retaliating',\n",
       " 'sensibilities-and',\n",
       " 'rawness',\n",
       " 'stopping',\n",
       " 'near-unintelligble',\n",
       " 'hipper',\n",
       " 'directoral',\n",
       " 'narrowed',\n",
       " 'STAKEOUT',\n",
       " 'Rage',\n",
       " 'GHOSTS',\n",
       " 'squalor',\n",
       " 'Larisa',\n",
       " 'armada',\n",
       " 'Hara',\n",
       " 'countenance',\n",
       " 'jogger',\n",
       " 'undeserving',\n",
       " 'seek',\n",
       " 'afternoons',\n",
       " 'progress',\n",
       " 'vaccine',\n",
       " '44-year-old',\n",
       " 'three-day',\n",
       " 'Shooting',\n",
       " 'understandably',\n",
       " 'Sentinels',\n",
       " 'morsels',\n",
       " 'when',\n",
       " 'Analysis',\n",
       " 'five',\n",
       " '4AM',\n",
       " 'underachieving',\n",
       " 'Consul',\n",
       " 'undertaken',\n",
       " 'capture',\n",
       " 'bungles',\n",
       " 'co-writer',\n",
       " 'Deputy',\n",
       " 'self-help',\n",
       " 'sub-inspired',\n",
       " 'Fox',\n",
       " 'STRONG',\n",
       " 'Angelo',\n",
       " 'Mimms',\n",
       " 'Sprinkle',\n",
       " 'Helsinki',\n",
       " 'covertly',\n",
       " 'gales',\n",
       " 'undiscovered',\n",
       " 'Prokofiev',\n",
       " 'Rains',\n",
       " 'farmer',\n",
       " 'Shekhar',\n",
       " 'scatter',\n",
       " 'Mandell',\n",
       " 'Jonnie',\n",
       " 'GO',\n",
       " 'crisis',\n",
       " 'Ross',\n",
       " 'Instantly',\n",
       " 'swiss',\n",
       " 'clichéd',\n",
       " 'Jjaks',\n",
       " 'REAR',\n",
       " 'materialistic',\n",
       " 'disciples',\n",
       " 'garden',\n",
       " 'sadomasochism',\n",
       " 'ulation',\n",
       " 'anti-male',\n",
       " 'painkillers',\n",
       " 'definitly',\n",
       " 'allure',\n",
       " 'grovel',\n",
       " 'cobbling',\n",
       " 'send-ups',\n",
       " 'Alfredo',\n",
       " 'EVERYONE',\n",
       " 'mountain-climber',\n",
       " 'timeframe',\n",
       " 'Henriksen',\n",
       " 'misfire',\n",
       " 'major',\n",
       " 'bongos',\n",
       " 'Bobcat',\n",
       " 'jerkish',\n",
       " 'Charmed',\n",
       " 'dealing',\n",
       " 'small-scale',\n",
       " 'meteors',\n",
       " 'Pzoniaks',\n",
       " 'Ciaran',\n",
       " 'LIB',\n",
       " 'near-certain',\n",
       " 'trading',\n",
       " 'extort',\n",
       " 'Clare',\n",
       " 'dictated',\n",
       " 'Jean-Luc',\n",
       " 'babes',\n",
       " 'subsumed',\n",
       " 'cross-country',\n",
       " 'transmission',\n",
       " 'assignments',\n",
       " 'over-the-hill',\n",
       " 'counter-terrorist',\n",
       " 'casually',\n",
       " 'do-whatever-it-takes',\n",
       " 'canines',\n",
       " 'glue',\n",
       " 'Adolph',\n",
       " 'Rome',\n",
       " 'refuse',\n",
       " 'lurks',\n",
       " 'BRADY',\n",
       " 'doted',\n",
       " 'Jane',\n",
       " 'soldering',\n",
       " 'vista',\n",
       " 'WWF',\n",
       " 'McCamus',\n",
       " 'unbreakable',\n",
       " 'a-plenty',\n",
       " 'Eventually',\n",
       " 'specifics',\n",
       " 'off-track',\n",
       " 'adult-oriented',\n",
       " 'pronto',\n",
       " 'PUBLIC',\n",
       " 'Bunker',\n",
       " 'Schuster',\n",
       " 'Britisher',\n",
       " 'Thewlis',\n",
       " 'Freeway',\n",
       " 'Aging',\n",
       " 'genial',\n",
       " 'Kwietniowski',\n",
       " 'troublemaker',\n",
       " 'fools',\n",
       " 'results.out',\n",
       " 'fluid',\n",
       " 'Asshole',\n",
       " 'Fools',\n",
       " 'pearly',\n",
       " 'youngest',\n",
       " 'progressively',\n",
       " 'luggage',\n",
       " 'decreased',\n",
       " 'Singleton',\n",
       " 'smarter-and',\n",
       " 'nuked-out',\n",
       " 'closed-down',\n",
       " 'Kenneth',\n",
       " 'destiny',\n",
       " 'gloomily',\n",
       " 'age-old',\n",
       " 'joker',\n",
       " 'aloud',\n",
       " 'Stormtrooper',\n",
       " 'Yugoslavia',\n",
       " 'Diesl',\n",
       " 'partygoers',\n",
       " 'sodomy',\n",
       " 'mucus',\n",
       " 'savings',\n",
       " 'rented',\n",
       " 'panting',\n",
       " 'stageromance',\n",
       " 'Dogme',\n",
       " 'minutes-that',\n",
       " 'Overdrawn',\n",
       " 'babe-thank',\n",
       " 'high-class',\n",
       " 'travels',\n",
       " 'plate',\n",
       " 'tinge',\n",
       " 'transaction',\n",
       " 'Ben',\n",
       " 'Lucy',\n",
       " 'Hollywood-a',\n",
       " 'continued',\n",
       " 'MacDonald',\n",
       " 'wee',\n",
       " 'REASON',\n",
       " 'Felliniesque',\n",
       " 'crystal',\n",
       " 'unrated',\n",
       " 'Greenaway',\n",
       " 'Biao',\n",
       " 'Cog',\n",
       " 'decides',\n",
       " 'yokel',\n",
       " 'Sr.',\n",
       " 'Guzman',\n",
       " 'experiencing',\n",
       " 'Pinkett',\n",
       " 'gym',\n",
       " 'ensemble',\n",
       " 'channels',\n",
       " '?????',\n",
       " 'Method',\n",
       " 'Performance',\n",
       " '85',\n",
       " 'friend-friend',\n",
       " 'ballet-type',\n",
       " 'Landon',\n",
       " 'likesubplots',\n",
       " 'mothers-in-law',\n",
       " 'Sandahl',\n",
       " 'Evangelista',\n",
       " 'READY',\n",
       " 'glean',\n",
       " 'stow',\n",
       " 'mob-style',\n",
       " 'Picture',\n",
       " 'co-creator',\n",
       " 'them.-Grocery',\n",
       " 'popsicle',\n",
       " 'Directors',\n",
       " 'ex-journalist',\n",
       " 'prosperity',\n",
       " 'bomber',\n",
       " 'anchors',\n",
       " 'Korean',\n",
       " 'storybook',\n",
       " 'Ward',\n",
       " 'moderately',\n",
       " 'Steele',\n",
       " 'Dutton',\n",
       " 'INTENTIONS',\n",
       " 'Winona',\n",
       " '1998',\n",
       " 'sophomore',\n",
       " 'heated',\n",
       " 'values',\n",
       " 'super-impaling',\n",
       " 'door',\n",
       " 'developments-all',\n",
       " 'Ratzenberger',\n",
       " 'OK',\n",
       " 'red-hot',\n",
       " 'coincided',\n",
       " 'mind-bogglingly',\n",
       " 'Balbricker',\n",
       " 'Pushing',\n",
       " 'ally',\n",
       " 'Rocket',\n",
       " 'directors-like',\n",
       " 'economics',\n",
       " 'Schellhardt',\n",
       " 'relationships',\n",
       " 'Swatch',\n",
       " 'trees',\n",
       " 'Armando',\n",
       " 'upwards',\n",
       " 'bluster',\n",
       " 'Mad',\n",
       " 'playsdifferent',\n",
       " 'Kimba',\n",
       " 'tint',\n",
       " 'pastel',\n",
       " 'joy-provider',\n",
       " 'princess-guarding',\n",
       " 'penchent',\n",
       " 'touts',\n",
       " 'Conversely',\n",
       " 'Pete',\n",
       " 'Bardsley',\n",
       " 'fool',\n",
       " 'Frankenstein',\n",
       " 'researchers',\n",
       " 'Skelton',\n",
       " 'burrow',\n",
       " 'wry',\n",
       " 'Guilty',\n",
       " 'payoff',\n",
       " 'trumping',\n",
       " 'zit',\n",
       " 'combative',\n",
       " 'Elwes',\n",
       " 'double-bill',\n",
       " 'unintentionally',\n",
       " 'dynamites',\n",
       " 'double-barreled',\n",
       " 'fiesty',\n",
       " 'bend',\n",
       " 'publish',\n",
       " 'Hawkes',\n",
       " 'blades',\n",
       " 'peaceful',\n",
       " 'seemingly-impregnable',\n",
       " 'ran',\n",
       " 'soured',\n",
       " 'Jurassic',\n",
       " 're-watched',\n",
       " 'Maron',\n",
       " 'ASSOCIATION',\n",
       " 'does-a',\n",
       " 'hedgetrimmers',\n",
       " 'bustling',\n",
       " 'anime',\n",
       " 'FM',\n",
       " 'underlines',\n",
       " 'hole-in-the-wall',\n",
       " 'hardware',\n",
       " 'dry',\n",
       " 'cryo-freeze',\n",
       " 'closer',\n",
       " 'Videodrome',\n",
       " 'Showgirls',\n",
       " 'writerly',\n",
       " 'operators',\n",
       " 'seminary',\n",
       " '70',\n",
       " 'Manor',\n",
       " 'fin',\n",
       " 'Olen',\n",
       " 'R-rated',\n",
       " 'oddities',\n",
       " 'prologues',\n",
       " 'Denueve',\n",
       " 'Luhrman',\n",
       " 'Mustang',\n",
       " 'Skeet',\n",
       " 'quicksand-one',\n",
       " 'made-for-Disney',\n",
       " 'unimpressive',\n",
       " 'SHARKS-who',\n",
       " 'Snorkle',\n",
       " 'coaxing',\n",
       " 'paralleled',\n",
       " 'Edina',\n",
       " 'Leave',\n",
       " 'Subtle',\n",
       " 'header',\n",
       " 'acclaim',\n",
       " 'countries',\n",
       " 'RIVER',\n",
       " 'core',\n",
       " 'perused',\n",
       " 'c-word',\n",
       " 'godmother',\n",
       " 'FLIRTING',\n",
       " 'fame-hungry',\n",
       " 'This',\n",
       " 'innuendos',\n",
       " 'Dina',\n",
       " '------',\n",
       " 'malleability',\n",
       " 'renograde',\n",
       " 'tuning-up',\n",
       " 'outacts',\n",
       " 'brims',\n",
       " 'undisputed',\n",
       " 'studs',\n",
       " 'ballerina',\n",
       " 'Abdul-Jabbar',\n",
       " 'overprotective',\n",
       " 'Salvadoran',\n",
       " 'reflexes',\n",
       " 'slickster',\n",
       " 'Endoskeleton',\n",
       " 'five-year-old',\n",
       " 'Ren',\n",
       " 'ringer',\n",
       " 'frills',\n",
       " 'eroticize',\n",
       " 'Bradford',\n",
       " 'costar',\n",
       " 'Patrick',\n",
       " 'tires',\n",
       " 'Egypt',\n",
       " 'shirtless',\n",
       " 'GOOD',\n",
       " 'chickenon',\n",
       " 'wrap-up',\n",
       " 'unerringly',\n",
       " 'LOVER',\n",
       " 'sequences',\n",
       " 'Mazzello',\n",
       " 'DIVA',\n",
       " 'fingertips',\n",
       " 'OBSESSION',\n",
       " 'accompaniment',\n",
       " 'courtoom',\n",
       " 'childlike',\n",
       " 'rapids',\n",
       " 'probably',\n",
       " 'Trash',\n",
       " 'racy',\n",
       " 'NIGHTIE',\n",
       " 'MONTY',\n",
       " 'Syndow',\n",
       " 'Farrelly-funny',\n",
       " 'poured',\n",
       " 'leaks',\n",
       " 'diminishing',\n",
       " 'Flew',\n",
       " 'plot-driven',\n",
       " 'TRILOGY',\n",
       " 'flaunted',\n",
       " 'chanteuse',\n",
       " 'gloppy',\n",
       " 'honk',\n",
       " 'Pictures',\n",
       " 'redhead',\n",
       " 'WARS',\n",
       " 'Janssen',\n",
       " 'Mast',\n",
       " 'MEANY',\n",
       " 'trailer',\n",
       " 'Shell',\n",
       " 'JUDGEMENT',\n",
       " 'survivor',\n",
       " 'varied',\n",
       " 'upsurge',\n",
       " 'articles',\n",
       " 'screw-ups',\n",
       " 'paradoxically',\n",
       " 'slaver',\n",
       " 'Baily-John',\n",
       " 'Valentina',\n",
       " 'Trier',\n",
       " 'doppelgangers',\n",
       " 'looking',\n",
       " 'Shagadellic',\n",
       " 'cutsie',\n",
       " 'persues',\n",
       " 'savage',\n",
       " 'makeshift',\n",
       " 'sarge',\n",
       " 'peddling',\n",
       " 'Savvy',\n",
       " 'blips',\n",
       " 'choreography',\n",
       " 'chuckd21@leading.net',\n",
       " 'discreetly',\n",
       " 'subtitling',\n",
       " 'Meir',\n",
       " 'true-to-heart',\n",
       " 'Whoever',\n",
       " 'Sax',\n",
       " 'ungodly',\n",
       " 'Bo-oooooring',\n",
       " 'asmonths',\n",
       " 'JEE-zus',\n",
       " 'Benton',\n",
       " 'Go-Go',\n",
       " 'Gun',\n",
       " 'decent',\n",
       " 'Pitt',\n",
       " 'FRIENDS',\n",
       " 'cheery',\n",
       " 'cherry-red',\n",
       " 'Slattery',\n",
       " 'dissipated',\n",
       " 'Balk',\n",
       " 'Questionable',\n",
       " 'agreeably',\n",
       " 'wide-spread',\n",
       " 'traffic',\n",
       " 'weirdos',\n",
       " 'electrocution',\n",
       " 'SIMON',\n",
       " 'spitting',\n",
       " 'discards',\n",
       " 'Ogden',\n",
       " 'Audre',\n",
       " 'one-scene',\n",
       " 'NORAD',\n",
       " 'Northam',\n",
       " 'passangers',\n",
       " 'word-a',\n",
       " 'Ba',\n",
       " 'whines',\n",
       " 'slowing',\n",
       " 'ha',\n",
       " 'Player',\n",
       " 'tape-to-film',\n",
       " 'individual',\n",
       " 'compassionate',\n",
       " 'compilation',\n",
       " 'Jagdish',\n",
       " 'faults',\n",
       " 'prisoner',\n",
       " 'relies',\n",
       " 'white-bread',\n",
       " 'desensitization',\n",
       " 'affliction',\n",
       " 'sighs',\n",
       " 'profane-filled',\n",
       " 'pseudoerotic',\n",
       " 'Redd',\n",
       " 'Doogie-er',\n",
       " 'Suo',\n",
       " 'Cohagen',\n",
       " 'hairpin',\n",
       " 'Lotte',\n",
       " 'Hood',\n",
       " 'confessing',\n",
       " 'sock-em',\n",
       " 'WHAT',\n",
       " 'word-of-mouth',\n",
       " 'charisma',\n",
       " 'Valiant',\n",
       " '1960s-age',\n",
       " 'lever',\n",
       " 'Landis',\n",
       " 'Easily-angered',\n",
       " 'GREAT',\n",
       " 'involuntarily',\n",
       " 'term',\n",
       " 'pomp',\n",
       " '6',\n",
       " 'slave-owners',\n",
       " 'gratuities',\n",
       " 'kidnapper/murderer',\n",
       " 'centennial',\n",
       " 'realizes',\n",
       " 'creepy',\n",
       " 'MFM',\n",
       " 'dampened',\n",
       " 'devotion',\n",
       " 'touch',\n",
       " 'drivin',\n",
       " 'Kelley',\n",
       " 'hapless',\n",
       " 'intersplices',\n",
       " 'poor-taste',\n",
       " 'bodied',\n",
       " 'revere',\n",
       " 'memoir',\n",
       " 'Hanover',\n",
       " 'synergy',\n",
       " 'Bremner',\n",
       " 'furrier',\n",
       " 'vegetable',\n",
       " 'Leo',\n",
       " 'Syndrome',\n",
       " 'complicates',\n",
       " 'one-upping',\n",
       " 'incisive',\n",
       " 'angelic-appearing',\n",
       " 'Trying',\n",
       " 'wits',\n",
       " 'Leguiziamo',\n",
       " 'poll-takers',\n",
       " 'Starkly',\n",
       " 'bewilder',\n",
       " 'Sir',\n",
       " 'Norton',\n",
       " 'blathers',\n",
       " 'overscored',\n",
       " 'stealthy',\n",
       " 'Catherine',\n",
       " 'i.e',\n",
       " 'implants',\n",
       " 'Sight',\n",
       " 'reared',\n",
       " 'CON-AIR',\n",
       " 'revisiting',\n",
       " 'excitment',\n",
       " 'scarcely',\n",
       " 'Edwards',\n",
       " 'Roll',\n",
       " 'FALLS',\n",
       " 'pitch',\n",
       " 'Chan-film',\n",
       " 'shalt',\n",
       " 'powers-of-10',\n",
       " 'setting-intensified',\n",
       " '1999-minutes',\n",
       " 'gem',\n",
       " 'score',\n",
       " 'COMPANY',\n",
       " 'Beginning',\n",
       " 'pounders',\n",
       " 'Majorino',\n",
       " 'Ashmore',\n",
       " 'Distracted',\n",
       " 'pouty-lips',\n",
       " 'impotent',\n",
       " 'passages',\n",
       " 'Michael',\n",
       " 'rocked',\n",
       " 'sickly',\n",
       " 'geeks',\n",
       " 'Ellsworth',\n",
       " 'sprees',\n",
       " 'misunderstandings',\n",
       " 'aromas',\n",
       " 'Prosky',\n",
       " 'aped',\n",
       " 'harnessed',\n",
       " 'influences',\n",
       " 'horror-movie',\n",
       " 'photographer-punching',\n",
       " 'protocol',\n",
       " 'generates',\n",
       " 'dumping',\n",
       " 'insane',\n",
       " 'ANDROMEDA',\n",
       " 'visualizing',\n",
       " 'ILM',\n",
       " 'graft',\n",
       " 'hectic',\n",
       " 'Xin-Xin',\n",
       " 'motorcycles',\n",
       " 'film-Tatooine',\n",
       " 'notoriously',\n",
       " 'crow',\n",
       " 'high-tech',\n",
       " 'premier',\n",
       " 'Met',\n",
       " 'Chappelle',\n",
       " 'Sze-Man',\n",
       " 'cool-as-hell',\n",
       " 'Gumpian',\n",
       " 'animal-hater',\n",
       " 'Shaggy',\n",
       " 'mosh',\n",
       " 'bowels',\n",
       " 'Mayfield-directed',\n",
       " 'apart',\n",
       " 'surprisingly',\n",
       " 'ensures',\n",
       " 'UNTIL',\n",
       " 'perpetuation',\n",
       " 'Unavoidable',\n",
       " 'mundane',\n",
       " 'Costanza',\n",
       " 'twin',\n",
       " 'Virtually',\n",
       " 'matter',\n",
       " 'peels',\n",
       " 'relevant',\n",
       " 'challenger',\n",
       " 'Ghibli',\n",
       " 'grisly-faced',\n",
       " 'priest',\n",
       " 'me-had',\n",
       " 'Yessssss',\n",
       " 'sympathize-then',\n",
       " 'Bachmann',\n",
       " 'Ratso',\n",
       " 'hotcakes',\n",
       " 'bump',\n",
       " 'Magnolia',\n",
       " 'Chernobyl',\n",
       " 'owing',\n",
       " 'out-get',\n",
       " 'rid',\n",
       " ...}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.extractReviewTokens(corpus.reviews[0])\n",
    "SVM.extractVocabulary(corpus.reviews)\n",
    "SVM.vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ' '.join(corpus.reviews[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 40113), 700)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer()\n",
    "X = count_vec.fit_transform(np.array([' '.join(rev[1]) for rev in corpus.reviews]))\n",
    "X.shape, len(corpus.reviews[0][1])\n",
    "# X_train_counts = count_vec.fit_transform([rev[1] for rev in corpus.reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using SVM 10-fold cross-eval ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-37c39175f5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- classifying reviews using SVM 10-fold cross-eval ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVMText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscard_closed_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msvm_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {SVM.getAccuracy():.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLMI13/Analysis.py\u001b[0m in \u001b[0;36mcrossValidate\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfold_j\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfold_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLMI13/Classifiers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, reviews)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m    338\u001b[0m         \u001b[0;31m# function to determine features in training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;31m# reset SVM classifier and train SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/MLMI13/Classifiers.py\u001b[0m in \u001b[0;36mgetFeatures\u001b[0;34m(self, reviews)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;31m# extract tokens per review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mreview_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractReviewTokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;31m# get vocab and get sparse vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO Q6 and 6.1\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = SVM.getFeatures(corpus.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 200)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus.train), len(corpus.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using Naive Bayes on held-out test set ---\n",
      "Accuracy without smoothing: 0.46\n"
     ]
    }
   ],
   "source": [
    "# question 1.0\n",
    "print(\"--- classifying reviews using Naive Bayes on held-out test set ---\")\n",
    "NB=NaiveBayesText(smoothing=False,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "# store predictions from classifier\n",
    "non_smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy without smoothing: {NB.getAccuracy():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using smoothing: 0.77\n",
      "results using smoothing are significant with respect to no smoothing\n"
     ]
    }
   ],
   "source": [
    "# question 2.0\n",
    "# use smoothing\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "smoothed_preds=NB.predictions\n",
    "# saving this for use later\n",
    "num_non_stemmed_features=len(NB.vocabulary)\n",
    "print(f\"Accuracy using smoothing: {NB.getAccuracy():.2f}\")\n",
    "\n",
    "\n",
    "# question 2.1\n",
    "# see if smoothing significantly improves results\n",
    "p_value=signTest.getSignificance(non_smoothed_preds,smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing are {significance} with respect to no smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_idx = 12\n",
    "review_idx % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using 10-fold cross-evaluation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcollins/Dropbox (MIT)/MLMI13/Analysis.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_files = np.array([np.array(corpus.folds[fold_j]) for fold_j in range(num_folds) if fold_j != fold_i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.814\n",
      "Std. Dev: 0.021424285285628522\n"
     ]
    }
   ],
   "source": [
    "# question 3.0\n",
    "print(\"--- classifying reviews using 10-fold cross-evaluation ---\")\n",
    "# using previous instantiated object\n",
    "NB.crossValidate(corpus)\n",
    "# using cross-eval for smoothed predictions from now on\n",
    "smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ee7a5883d133>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_data = np.array([np.array(corpus.folds[j]) for j in range(10) if j != fold_i])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1800, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "fold_i = 0 \n",
    "train_data = np.array([np.array(corpus.folds[j]) for j in range(10) if j != fold_i])\n",
    "np.shape(np.reshape(train_data, [train_data.shape[0]*train_data.shape[1], train_data.shape[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 200, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- stemming corpus ---\n",
      "num train: 1800, num test: 200\n",
      "tot num reviews: 2000\n",
      "--- cross-validating NB using stemming ---\n",
      "Accuracy: 0.832\n",
      "Std. Dev: 0.015\n",
      "results using stemming are not significant with respect to no stemming\n",
      "--- determining the number of features before/after stemming ---\n",
      "num features, non-stemmed: 60261 vs. num features, stemmed: 526358\n"
     ]
    }
   ],
   "source": [
    "# question 4.0\n",
    "print(\"--- stemming corpus ---\")\n",
    "# retrieve corpus with tokenized text and stemming (using porter)\n",
    "stemmed_corpus=MovieReviewCorpus(stemming=True,pos=False)\n",
    "print(\"--- cross-validating NB using stemming ---\")\n",
    "NB.crossValidate(stemmed_corpus)\n",
    "stemmed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n",
    "# TODO Q4.1\n",
    "# see if stemming significantly improves results on smoothed NB (both did cv)\n",
    "p_value=signTest.getSignificance(stemmed_preds,smoothed_preds) # note compared against version w/ smoothing! \n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using stemming are {significance} with respect to no stemming\")\n",
    "\n",
    "# TODO Q4.2\n",
    "print(\"--- determining the number of features before/after stemming ---\")\n",
    "# (**) changing the number of features == changing the number of words in the vocab \n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "num_stemmed_features = len(NB.vocabulary)\n",
    "print(f\"num features, non-stemmed: {num_non_stemmed_features} vs. num features, stemmed: {num_bow_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- cross-validating naive bayes using smoothing and bigrams ---\n",
      "Accuracy: 0.83\n",
      "Std. Dev: 0.02\n",
      "results using smoothing and bigrams are not significant with respect to smoothing only\n",
      "num features for [model] (Q3): 60261 vs. num features BoW: 526358\n"
     ]
    }
   ],
   "source": [
    "# question Q5.0\n",
    "# cross-validate model using smoothing and bigrams\n",
    "print(\"--- cross-validating naive bayes using smoothing and bigrams ---\")\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "NB.crossValidate(corpus)\n",
    "smoothed_and_bigram_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.2f}\")\n",
    "\n",
    "\n",
    "# see if bigrams significantly improves results on smoothed NB only\n",
    "p_value=signTest.getSignificance(smoothed_preds,smoothed_and_bigram_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing and bigrams are {signifance} with respect to smoothing only\")\n",
    "\n",
    "\n",
    "# TODO Q5.1\n",
    "# katie: from q3 (num_non_stemmed_features)\n",
    "num_bow_features = len(NB.vocabulary)\n",
    "print(f\"num features for [model] (Q3): {num_non_stemmed_features} vs. num features BoW: {num_bow_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using SVM 10-fold cross-eval ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcollins/Dropbox (MIT)/MLMI13/Analysis.py:29: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_files = np.array([np.array(corpus.folds[fold_j]) for fold_j in range(num_folds) if fold_j != fold_i])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SVMText' object has no attribute 'len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-37c39175f5f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- classifying reviews using SVM 10-fold cross-eval ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVMText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrigrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscard_closed_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossValidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0msvm_preds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Accuracy: {SVM.getAccuracy():.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/MLMI13/Analysis.py\u001b[0m in \u001b[0;36mcrossValidate\u001b[0;34m(self, corpus)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold_j\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_j\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfold_j\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfold_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/MLMI13/Classifiers.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, reviews)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \"\"\"\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# function to determine features in training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# reset SVM classifier and train SVM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox (MIT)/MLMI13/Classifiers.py\u001b[0m in \u001b[0;36mgetFeatures\u001b[0;34m(self, reviews)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;31m# review feature = vec of size len(Vocab)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;31m# each element represents count of that feature in the review\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;31m# input_feats = np.zeros(len(num_features))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVMText' object has no attribute 'len'"
     ]
    }
   ],
   "source": [
    "# TODO Q6 and 6.1\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy():.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- adding in POS information to corpus ---\n",
      "--- training svm on word+pos features ----\n",
      "--- training svm discarding closed-class words ---\n"
     ]
    }
   ],
   "source": [
    "# TODO Q7\n",
    "print(\"--- adding in POS information to corpus ---\")\n",
    "print(\"--- training svm on word+pos features ----\")\n",
    "print(\"--- training svm discarding closed-class words ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- using document embeddings ---\n"
     ]
    }
   ],
   "source": [
    "# question 8.0\n",
    "print(\"--- using document embeddings ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
