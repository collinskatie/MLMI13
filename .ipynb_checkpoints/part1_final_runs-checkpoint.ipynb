{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Corpora import MovieReviewCorpus\n",
    "from Lexicon import SentimentLexicon\n",
    "from Statistics import SignTest\n",
    "from Classifiers import NaiveBayesText, SVMText\n",
    "from Extensions import SVMDoc2Vec, DocFeaturizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num train: 1800, num test: 200\n",
      "tot num reviews: 2000\n",
      "--- classifying reviews using sentiment lexicon  ---\n",
      "token-only results: 0.68\n",
      "magnitude results: 0.69\n",
      "magnitude lexicon results are not significant with respect to token-only\n"
     ]
    }
   ],
   "source": [
    "# retrieve corpus\n",
    "corpus=MovieReviewCorpus(stemming=False,pos=False)\n",
    "\n",
    "# use sign test for all significance testing\n",
    "signTest=SignTest()\n",
    "\n",
    "print(\"--- classifying reviews using sentiment lexicon  ---\")\n",
    "\n",
    "# read in lexicon\n",
    "lexicon=SentimentLexicon()\n",
    "\n",
    "# on average there are more positive than negative words per review (~7.13 more positive than negative per review)\n",
    "# to take this bias into account will use threshold (roughly the bias itself) to make it harder to classify as positive\n",
    "#Â todo: vary this!!! \n",
    "threshold=8\n",
    "\n",
    "# NOTE: from katie to self -- play w/ changing the threshold value! \n",
    "\n",
    "# question 0.1\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=False)\n",
    "token_preds=lexicon.predictions\n",
    "print(f\"token-only results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "lexicon.classify(corpus.reviews,threshold,magnitude=True)\n",
    "magnitude_preds=lexicon.predictions\n",
    "print(f\"magnitude results: {lexicon.getAccuracy():.2f}\")\n",
    "\n",
    "# question 0.2\n",
    "p_value=signTest.getSignificance(token_preds,magnitude_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"magnitude lexicon results are {significance} with respect to token-only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using Naive Bayes on held-out test set ---\n",
      "Accuracy without smoothing: 0.48\n"
     ]
    }
   ],
   "source": [
    "# question 1.0\n",
    "print(\"--- classifying reviews using Naive Bayes on held-out test set ---\")\n",
    "NB=NaiveBayesText(smoothing=False,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "# store predictions from classifier\n",
    "non_smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy without smoothing: {NB.getAccuracy():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using smoothing: 0.78\n",
      "results using smoothing are significant with respect to no smoothing\n"
     ]
    }
   ],
   "source": [
    "# question 2.0\n",
    "# use smoothing\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=False,trigrams=False,discard_closed_class=False)\n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "smoothed_preds=NB.predictions\n",
    "# saving this for use later\n",
    "num_non_stemmed_features=len(NB.vocabulary)\n",
    "print(f\"Accuracy using smoothing: {NB.getAccuracy():.2f}\")\n",
    "\n",
    "# question 2.1\n",
    "# see if smoothing significantly improves results\n",
    "p_value=signTest.getSignificance(non_smoothed_preds,smoothed_preds)\n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing are {significance} with respect to no smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- classifying reviews using 10-fold cross-evaluation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kcollins/MLMI13/Analysis.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_files = np.array([np.array(corpus.folds[fold_j]) for fold_j in range(num_folds) if fold_j != fold_i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.818\n",
      "Std. Dev: 0.015033296378372876\n"
     ]
    }
   ],
   "source": [
    "# question 3.0\n",
    "print(\"--- classifying reviews using 10-fold cross-evaluation ---\")\n",
    "# using previous instantiated object\n",
    "NB.crossValidate(corpus)\n",
    "# using cross-eval for smoothed predictions from now on\n",
    "smoothed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy(cross_val_preds=True):.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7fd803d6f3d0>,\n",
       "  <matplotlib.lines.Line2D at 0x7fd803d6f730>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7fd803d6fa90>,\n",
       "  <matplotlib.lines.Line2D at 0x7fd803d6fdf0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7fd803d6f070>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7fd803d7b190>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7fd803d7b4f0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(NB.score_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4.0\n",
    "print(\"--- stemming corpus ---\")\n",
    "# retrieve corpus with tokenized text and stemming (using porter)\n",
    "stemmed_corpus=MovieReviewCorpus(stemming=True,pos=False)\n",
    "print(\"--- cross-validating NB using stemming ---\")\n",
    "NB.crossValidate(stemmed_corpus)\n",
    "stemmed_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy(cross_val_preds=True):.3f}\")\n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.3f}\")\n",
    "\n",
    "# TODO Q4.1\n",
    "# see if stemming significantly improves results on smoothed NB (both did cv)\n",
    "p_value=signTest.getSignificance(stemmed_preds,smoothed_preds) # note compared against version w/ smoothing! \n",
    "significance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using stemming are {significance} with respect to no stemming\")\n",
    "\n",
    "# TODO Q4.2\n",
    "print(\"--- determining the number of features before/after stemming ---\")\n",
    "# (**) changing the number of features == changing the number of words in the vocab \n",
    "NB.train(corpus.train)\n",
    "NB.test(corpus.test)\n",
    "num_stemmed_features = len(NB.vocabulary)\n",
    "print(f\"num features, non-stemmed: {num_non_stemmed_features} vs. num features, stemmed: {num_stemmed_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question Q5.0\n",
    "# cross-validate model using smoothing and bigrams\n",
    "print(\"--- cross-validating naive bayes using smoothing and bigrams ---\")\n",
    "NB=NaiveBayesText(smoothing=True,bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "NB.crossValidate(corpus)\n",
    "smoothed_and_bigram_preds=NB.predictions\n",
    "print(f\"Accuracy: {NB.getAccuracy(cross_val_preds=True):.2f}\") \n",
    "print(f\"Std. Dev: {NB.getStdDeviation():.2f}\")\n",
    "\n",
    "\n",
    "# see if bigrams significantly improves results on smoothed NB only\n",
    "p_value=signTest.getSignificance(smoothed_preds,smoothed_and_bigram_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using smoothing and bigrams are {signifance} with respect to smoothing only\")\n",
    "\n",
    "\n",
    "# TODO Q5.1\n",
    "# katie: from q3 (num_non_stemmed_features)\n",
    "num_bow_features = len(NB.vocabulary)\n",
    "print(f\"num features for [model] (Q3): {num_non_stemmed_features} vs. num features BoW: {num_bow_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q6 and 6.1\n",
    "print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy(cross_val_preds=True):.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO Q6 and 6.1\n",
    "# corpus = MovieReviewCorpus(stemming=False,pos=False,use_imdb=True)\n",
    "# print(\"--- classifying reviews using SVM 10-fold cross-eval ---\")\n",
    "# SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "# SVM.train(corpus.train)\n",
    "# SVM.test(corpus.test)\n",
    "# svm_preds=SVM.predictions\n",
    "# print(f\"Accuracy: {SVM.getAccuracy():.2f}\") \n",
    "# print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Q7.0\n",
    "print(\"--- adding in POS information to corpus ---\")\n",
    "pos_corpus=MovieReviewCorpus(stemming=False,pos=True)\n",
    "print(\"--- training svm on word+pos features ----\")\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=False)\n",
    "SVM.crossValidate(pos_corpus)\n",
    "svm_pos_preds=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy(cross_val_preds=True):.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")\n",
    "p_value=signTest.getSignificance(svm_pos_preds,svm_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results using pos tags {signifance} with respect to not using pos tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: QUESTION 7.1\n",
    "print(\"--- training svm discarding closed-class words ---\") # QUESTION: do we not use POS here??\n",
    "SVM=SVMText(bigrams=True,trigrams=False,discard_closed_class=True)\n",
    "SVM.crossValidate(corpus)\n",
    "svm_preds_closed=SVM.predictions\n",
    "print(f\"Accuracy: {SVM.getAccuracy(cross_val_preds=True):.2f}\") \n",
    "print(f\"Std. Dev: {SVM.getStdDeviation():.2f}\")\n",
    "p_value=signTest.getSignificance(svm_preds_closed,svm_preds)\n",
    "signifance = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "print(f\"results discarding closed class {signifance} with respect to keeping the closed class\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
